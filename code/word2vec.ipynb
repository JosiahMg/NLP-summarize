{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Word2Vec in Gensim and making it work!\n",
    "\n",
    "The idea behind Word2Vec is pretty simple. We are making and assumption that you can tell the meaning of a word by the company it keeps. This is analogous to the saying *show me your friends, and I'll tell who you are*. So if you have two words that have very similar neighbors (i.e. the usage context is about the same), then these words are probably quite similar in meaning or are at least highly related. For example, the words `shocked`,`appalled` and `astonished` are typically used in a similar context. \n",
    "\n",
    "In this tutorial, you will learn how to use the Gensim implementation of Word2Vec and actually get it to work! I have heard a lot of complaints about poor performance etc, but its really a combination of two things, (1) your input data and (2) your parameter settings. Note that the training algorithms in this package were ported from the [original Word2Vec implementation by Google](https://arxiv.org/pdf/1301.3781.pdf) and extended with additional functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and logging\n",
    "\n",
    "First, we start with our imports and get logging established:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed and set up logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Next, is our dataset. The secret to getting Word2Vec really working for you is to have lots and lots of text data. In this case I am going to use data from the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset. This dataset has full user reviews of cars and hotels. I have specifically concatenated all of the hotel reviews into one big file which is about 97MB compressed and 229MB uncompressed. We will use the compressed file for this tutorial. Each line in this file represents a hotel review. You can download the OpinRank Word2Vec dataset here.\n",
    "\n",
    "To avoid confusion, while gensim’s word2vec tutorial says that you need to pass it a sequence of sentences as its input, you can always pass it a whole review as a sentence (i.e. a much larger size of text), and it should not make much of a difference. \n",
    "\n",
    "Now, let's take a closer look at this data below by printing the first line. You can see that this is a pretty hefty review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file=\"../corpus/reviews_data.txt.gz\"\n",
    "\n",
    "with gzip.open (data_file, 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files into a list\n",
    "Now that we've had a sneak peak of our dataset, we can read it into a list so that we can pass this on to the Word2Vec model. Notice in the code below, that I am directly reading the \n",
    "compressed file. I'm also doing a mild pre-processing of the reviews using `gensim.utils.simple_preprocess (line)`. This does some basic pre-processing such as tokenization, lowercasing, etc and returns back a list of tokens (words). Documentation of this pre-processing method can be found on the official [Gensim documentation site](https://radimrehurek.com/gensim/utils.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 15:14:05,829 : INFO : reading file ../corpus/reviews_data.txt.gz...this may take a while\n",
      "2020-06-16 15:14:05,830 : INFO : read 0 reviews\n",
      "2020-06-16 15:14:07,817 : INFO : read 10000 reviews\n",
      "2020-06-16 15:14:09,694 : INFO : read 20000 reviews\n",
      "2020-06-16 15:14:11,842 : INFO : read 30000 reviews\n",
      "2020-06-16 15:14:13,865 : INFO : read 40000 reviews\n",
      "2020-06-16 15:14:16,273 : INFO : read 50000 reviews\n",
      "2020-06-16 15:14:18,415 : INFO : read 60000 reviews\n",
      "2020-06-16 15:14:20,336 : INFO : read 70000 reviews\n",
      "2020-06-16 15:14:22,033 : INFO : read 80000 reviews\n",
      "2020-06-16 15:14:23,837 : INFO : read 90000 reviews\n",
      "2020-06-16 15:14:25,513 : INFO : read 100000 reviews\n",
      "2020-06-16 15:14:27,177 : INFO : read 110000 reviews\n",
      "2020-06-16 15:14:28,918 : INFO : read 120000 reviews\n",
      "2020-06-16 15:14:30,661 : INFO : read 130000 reviews\n",
      "2020-06-16 15:14:32,520 : INFO : read 140000 reviews\n",
      "2020-06-16 15:14:34,608 : INFO : read 150000 reviews\n",
      "2020-06-16 15:14:37,770 : INFO : read 160000 reviews\n",
      "2020-06-16 15:14:41,485 : INFO : read 170000 reviews\n",
      "2020-06-16 15:14:45,184 : INFO : read 180000 reviews\n",
      "2020-06-16 15:14:46,927 : INFO : read 190000 reviews\n",
      "2020-06-16 15:14:49,472 : INFO : read 200000 reviews\n",
      "2020-06-16 15:14:51,923 : INFO : read 210000 reviews\n",
      "2020-06-16 15:14:53,775 : INFO : read 220000 reviews\n",
      "2020-06-16 15:14:55,516 : INFO : read 230000 reviews\n",
      "2020-06-16 15:14:58,427 : INFO : read 240000 reviews\n",
      "2020-06-16 15:15:00,279 : INFO : read 250000 reviews\n",
      "2020-06-16 15:15:01,249 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_input(input_file):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    \n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"read {0} reviews\".format (i))\n",
    "            # do some pre-processing and return a list of words for each review text\n",
    "            yield gensim.utils.simple_preprocess (line)\n",
    "\n",
    "# read the tokenized reviews into a list\n",
    "# each review item becomes a serries of words\n",
    "# so this becomes a list of lists\n",
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Done reading data file\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Word2Vec model\n",
    "\n",
    "Training the model is fairly straightforward. You just instantiate Word2Vec and pass the reviews that we read in the previous step (the `documents`). So, we are essentially passing on a list of lists. Where each list within the main list contains a set of tokens from a user review. Word2Vec uses all these tokens to internally create a vocabulary. And by vocabulary, I mean a set of unique words.\n",
    "\n",
    "After building the vocabulary, we just need to call `train(...)` to start training the Word2Vec model. Training on the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset takes about 10 minutes so please be patient while running your code on this dataset.\n",
    "\n",
    "Behind the scenes we are actually training a simple neural network with a single hidden layer. But, we are actually not going to use the neural network after training. Instead, the goal is to learn the weights of the hidden layer. These weights are essentially the word vectors that we’re trying to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 15:18:37,578 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2020-06-16 15:18:37,605 : INFO : collecting all words and their counts\n",
      "2020-06-16 15:18:37,606 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-06-16 15:18:38,079 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2020-06-16 15:18:38,414 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2020-06-16 15:18:38,888 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2020-06-16 15:18:39,247 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2020-06-16 15:18:39,692 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2020-06-16 15:18:40,121 : INFO : PROGRESS: at sentence #60000, processed 11013726 words, keeping 76786 word types\n",
      "2020-06-16 15:18:40,484 : INFO : PROGRESS: at sentence #70000, processed 12637528 words, keeping 83199 word types\n",
      "2020-06-16 15:18:40,820 : INFO : PROGRESS: at sentence #80000, processed 14099754 words, keeping 88459 word types\n",
      "2020-06-16 15:18:41,186 : INFO : PROGRESS: at sentence #90000, processed 15662152 words, keeping 93357 word types\n",
      "2020-06-16 15:18:41,545 : INFO : PROGRESS: at sentence #100000, processed 17164490 words, keeping 97886 word types\n",
      "2020-06-16 15:18:41,891 : INFO : PROGRESS: at sentence #110000, processed 18652295 words, keeping 102132 word types\n",
      "2020-06-16 15:18:42,193 : INFO : PROGRESS: at sentence #120000, processed 20152532 words, keeping 105923 word types\n",
      "2020-06-16 15:18:42,561 : INFO : PROGRESS: at sentence #130000, processed 21684333 words, keeping 110104 word types\n",
      "2020-06-16 15:18:43,161 : INFO : PROGRESS: at sentence #140000, processed 23330209 words, keeping 114108 word types\n",
      "2020-06-16 15:18:43,655 : INFO : PROGRESS: at sentence #150000, processed 24838757 words, keeping 118174 word types\n",
      "2020-06-16 15:18:44,086 : INFO : PROGRESS: at sentence #160000, processed 26390913 words, keeping 118670 word types\n",
      "2020-06-16 15:18:44,532 : INFO : PROGRESS: at sentence #170000, processed 27913919 words, keeping 123356 word types\n",
      "2020-06-16 15:18:44,796 : INFO : PROGRESS: at sentence #180000, processed 29535615 words, keeping 126748 word types\n",
      "2020-06-16 15:18:45,032 : INFO : PROGRESS: at sentence #190000, processed 31096462 words, keeping 129847 word types\n",
      "2020-06-16 15:18:45,274 : INFO : PROGRESS: at sentence #200000, processed 32805274 words, keeping 133255 word types\n",
      "2020-06-16 15:18:45,505 : INFO : PROGRESS: at sentence #210000, processed 34434201 words, keeping 136364 word types\n",
      "2020-06-16 15:18:45,773 : INFO : PROGRESS: at sentence #220000, processed 36083485 words, keeping 139418 word types\n",
      "2020-06-16 15:18:45,979 : INFO : PROGRESS: at sentence #230000, processed 37571765 words, keeping 142399 word types\n",
      "2020-06-16 15:18:46,195 : INFO : PROGRESS: at sentence #240000, processed 39138193 words, keeping 145232 word types\n",
      "2020-06-16 15:18:46,589 : INFO : PROGRESS: at sentence #250000, processed 40695052 words, keeping 147966 word types\n",
      "2020-06-16 15:18:46,767 : INFO : collected 150059 word types from a corpus of 41519358 raw words and 255404 sentences\n",
      "2020-06-16 15:18:46,770 : INFO : Loading a fresh vocabulary\n",
      "2020-06-16 15:18:49,617 : INFO : effective_min_count=2 retains 70537 unique words (47% of original 150059, drops 79522)\n",
      "2020-06-16 15:18:49,618 : INFO : effective_min_count=2 leaves 41439836 word corpus (99% of original 41519358, drops 79522)\n",
      "2020-06-16 15:18:49,820 : INFO : deleting the raw counts dictionary of 150059 items\n",
      "2020-06-16 15:18:49,837 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2020-06-16 15:18:49,838 : INFO : downsampling leaves estimated 30349251 word corpus (73.2% of prior 41439836)\n",
      "2020-06-16 15:18:50,031 : INFO : estimated required memory for 70537 words and 150 dimensions: 119912900 bytes\n",
      "2020-06-16 15:18:50,032 : INFO : resetting layer weights\n",
      "2020-06-16 15:19:01,287 : INFO : training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-06-16 15:19:02,324 : INFO : EPOCH 1 - PROGRESS: at 5.81% examples, 1780275 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:03,326 : INFO : EPOCH 1 - PROGRESS: at 10.88% examples, 1744031 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:04,332 : INFO : EPOCH 1 - PROGRESS: at 16.09% examples, 1771095 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:05,339 : INFO : EPOCH 1 - PROGRESS: at 20.98% examples, 1790112 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:06,352 : INFO : EPOCH 1 - PROGRESS: at 26.83% examples, 1804087 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:07,355 : INFO : EPOCH 1 - PROGRESS: at 33.48% examples, 1808573 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:08,363 : INFO : EPOCH 1 - PROGRESS: at 40.06% examples, 1817312 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:09,363 : INFO : EPOCH 1 - PROGRESS: at 46.56% examples, 1814564 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:10,375 : INFO : EPOCH 1 - PROGRESS: at 53.05% examples, 1823857 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:19:11,378 : INFO : EPOCH 1 - PROGRESS: at 59.55% examples, 1827445 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:12,382 : INFO : EPOCH 1 - PROGRESS: at 65.83% examples, 1824246 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:13,395 : INFO : EPOCH 1 - PROGRESS: at 71.95% examples, 1825388 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:14,404 : INFO : EPOCH 1 - PROGRESS: at 78.37% examples, 1833768 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:15,418 : INFO : EPOCH 1 - PROGRESS: at 84.19% examples, 1826895 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:16,419 : INFO : EPOCH 1 - PROGRESS: at 90.63% examples, 1829097 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:17,421 : INFO : EPOCH 1 - PROGRESS: at 96.56% examples, 1823249 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:17,901 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:19:17,914 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:19:17,916 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:19:17,916 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:19:17,917 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:19:17,922 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:19:17,924 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:19:17,926 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:19:17,932 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:19:17,934 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:19:17,935 : INFO : EPOCH - 1 : training on 41519358 raw words (30348079 effective words) took 16.6s, 1826119 effective words/s\n",
      "2020-06-16 15:19:18,941 : INFO : EPOCH 2 - PROGRESS: at 5.77% examples, 1775360 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:19,948 : INFO : EPOCH 2 - PROGRESS: at 11.36% examples, 1826759 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:20,950 : INFO : EPOCH 2 - PROGRESS: at 16.75% examples, 1854723 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:21,960 : INFO : EPOCH 2 - PROGRESS: at 21.96% examples, 1854449 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:22,971 : INFO : EPOCH 2 - PROGRESS: at 27.96% examples, 1862528 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:23,973 : INFO : EPOCH 2 - PROGRESS: at 34.51% examples, 1860898 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:24,973 : INFO : EPOCH 2 - PROGRESS: at 40.49% examples, 1838983 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:25,979 : INFO : EPOCH 2 - PROGRESS: at 46.62% examples, 1817796 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:19:26,988 : INFO : EPOCH 2 - PROGRESS: at 51.77% examples, 1779861 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:27,993 : INFO : EPOCH 2 - PROGRESS: at 57.61% examples, 1772816 words/s, in_qsize 18, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 15:19:29,009 : INFO : EPOCH 2 - PROGRESS: at 63.11% examples, 1754616 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:30,012 : INFO : EPOCH 2 - PROGRESS: at 68.24% examples, 1730987 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:31,018 : INFO : EPOCH 2 - PROGRESS: at 74.04% examples, 1729330 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:32,022 : INFO : EPOCH 2 - PROGRESS: at 79.47% examples, 1727771 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:33,031 : INFO : EPOCH 2 - PROGRESS: at 85.06% examples, 1726609 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:34,037 : INFO : EPOCH 2 - PROGRESS: at 90.49% examples, 1713808 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:35,037 : INFO : EPOCH 2 - PROGRESS: at 96.09% examples, 1709309 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:35,717 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:19:35,729 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:19:35,731 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:19:35,732 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:19:35,733 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:19:35,743 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:19:35,745 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:19:35,746 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:19:35,747 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:19:35,757 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:19:35,760 : INFO : EPOCH - 2 : training on 41519358 raw words (30348169 effective words) took 17.8s, 1702909 effective words/s\n",
      "2020-06-16 15:19:36,777 : INFO : EPOCH 3 - PROGRESS: at 5.38% examples, 1640971 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:37,782 : INFO : EPOCH 3 - PROGRESS: at 10.30% examples, 1636237 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:38,790 : INFO : EPOCH 3 - PROGRESS: at 15.19% examples, 1666211 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:39,791 : INFO : EPOCH 3 - PROGRESS: at 19.89% examples, 1681015 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:40,801 : INFO : EPOCH 3 - PROGRESS: at 24.72% examples, 1691651 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:41,805 : INFO : EPOCH 3 - PROGRESS: at 30.79% examples, 1685509 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:42,810 : INFO : EPOCH 3 - PROGRESS: at 36.72% examples, 1684862 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:43,821 : INFO : EPOCH 3 - PROGRESS: at 42.66% examples, 1679664 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:44,822 : INFO : EPOCH 3 - PROGRESS: at 48.49% examples, 1674774 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:45,825 : INFO : EPOCH 3 - PROGRESS: at 53.78% examples, 1664568 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:46,826 : INFO : EPOCH 3 - PROGRESS: at 59.16% examples, 1653006 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:47,829 : INFO : EPOCH 3 - PROGRESS: at 64.98% examples, 1650493 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:48,829 : INFO : EPOCH 3 - PROGRESS: at 70.60% examples, 1656136 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:49,831 : INFO : EPOCH 3 - PROGRESS: at 75.44% examples, 1639764 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:50,831 : INFO : EPOCH 3 - PROGRESS: at 80.02% examples, 1626902 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:51,833 : INFO : EPOCH 3 - PROGRESS: at 85.00% examples, 1620816 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:52,834 : INFO : EPOCH 3 - PROGRESS: at 90.71% examples, 1620060 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:19:53,846 : INFO : EPOCH 3 - PROGRESS: at 95.62% examples, 1608420 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:54,635 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:19:54,642 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:19:54,643 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:19:54,645 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:19:54,648 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:19:54,652 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:19:54,656 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:19:54,661 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:19:54,664 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:19:54,665 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:19:54,666 : INFO : EPOCH - 3 : training on 41519358 raw words (30351875 effective words) took 18.9s, 1605861 effective words/s\n",
      "2020-06-16 15:19:55,680 : INFO : EPOCH 4 - PROGRESS: at 4.83% examples, 1475985 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:56,683 : INFO : EPOCH 4 - PROGRESS: at 9.57% examples, 1493454 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:57,689 : INFO : EPOCH 4 - PROGRESS: at 13.40% examples, 1460529 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:19:58,694 : INFO : EPOCH 4 - PROGRESS: at 17.57% examples, 1464781 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:19:59,695 : INFO : EPOCH 4 - PROGRESS: at 21.59% examples, 1456598 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:00,696 : INFO : EPOCH 4 - PROGRESS: at 25.82% examples, 1463016 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:01,697 : INFO : EPOCH 4 - PROGRESS: at 31.62% examples, 1478354 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:02,703 : INFO : EPOCH 4 - PROGRESS: at 37.01% examples, 1488359 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:03,706 : INFO : EPOCH 4 - PROGRESS: at 42.67% examples, 1497568 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:04,718 : INFO : EPOCH 4 - PROGRESS: at 48.37% examples, 1506026 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:05,724 : INFO : EPOCH 4 - PROGRESS: at 53.70% examples, 1512640 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:06,728 : INFO : EPOCH 4 - PROGRESS: at 59.21% examples, 1517382 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:07,739 : INFO : EPOCH 4 - PROGRESS: at 64.81% examples, 1519604 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:08,753 : INFO : EPOCH 4 - PROGRESS: at 70.02% examples, 1523831 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:09,756 : INFO : EPOCH 4 - PROGRESS: at 75.43% examples, 1528090 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:10,759 : INFO : EPOCH 4 - PROGRESS: at 80.49% examples, 1532081 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:11,771 : INFO : EPOCH 4 - PROGRESS: at 85.56% examples, 1532754 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:20:12,773 : INFO : EPOCH 4 - PROGRESS: at 91.29% examples, 1536468 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:13,775 : INFO : EPOCH 4 - PROGRESS: at 96.77% examples, 1540125 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:14,317 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:20:14,324 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:20:14,330 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:20:14,332 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:20:14,335 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:20:14,338 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:20:14,339 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:20:14,346 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:20:14,347 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:20:14,349 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:20:14,350 : INFO : EPOCH - 4 : training on 41519358 raw words (30347537 effective words) took 19.7s, 1542222 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 15:20:15,356 : INFO : EPOCH 5 - PROGRESS: at 5.07% examples, 1566432 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:16,357 : INFO : EPOCH 5 - PROGRESS: at 10.01% examples, 1594482 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:17,363 : INFO : EPOCH 5 - PROGRESS: at 14.44% examples, 1587019 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:18,368 : INFO : EPOCH 5 - PROGRESS: at 18.90% examples, 1588179 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:19,373 : INFO : EPOCH 5 - PROGRESS: at 23.29% examples, 1588641 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:20,373 : INFO : EPOCH 5 - PROGRESS: at 28.63% examples, 1590683 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:20:21,375 : INFO : EPOCH 5 - PROGRESS: at 34.07% examples, 1583762 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:22,382 : INFO : EPOCH 5 - PROGRESS: at 39.55% examples, 1578945 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:23,386 : INFO : EPOCH 5 - PROGRESS: at 45.39% examples, 1578929 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:24,396 : INFO : EPOCH 5 - PROGRESS: at 49.70% examples, 1544993 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:25,402 : INFO : EPOCH 5 - PROGRESS: at 53.85% examples, 1517631 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:20:26,407 : INFO : EPOCH 5 - PROGRESS: at 59.19% examples, 1517771 words/s, in_qsize 20, out_qsize 1\n",
      "2020-06-16 15:20:27,415 : INFO : EPOCH 5 - PROGRESS: at 64.21% examples, 1508653 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:28,421 : INFO : EPOCH 5 - PROGRESS: at 69.51% examples, 1514067 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:29,432 : INFO : EPOCH 5 - PROGRESS: at 74.69% examples, 1513397 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:20:30,443 : INFO : EPOCH 5 - PROGRESS: at 79.34% examples, 1510107 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:20:31,449 : INFO : EPOCH 5 - PROGRESS: at 84.53% examples, 1514616 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:32,459 : INFO : EPOCH 5 - PROGRESS: at 89.84% examples, 1514193 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:20:33,472 : INFO : EPOCH 5 - PROGRESS: at 94.87% examples, 1510341 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:20:34,442 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:20:34,456 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:20:34,459 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:20:34,460 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:20:34,464 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:20:34,468 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:20:34,475 : INFO : EPOCH 5 - PROGRESS: at 99.94% examples, 1507742 words/s, in_qsize 3, out_qsize 1\n",
      "2020-06-16 15:20:34,476 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:20:34,477 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:20:34,477 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:20:34,484 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:20:34,485 : INFO : EPOCH - 5 : training on 41519358 raw words (30352994 effective words) took 20.1s, 1507918 effective words/s\n",
      "2020-06-16 15:20:34,486 : INFO : training on a 207596790 raw words (151748654 effective words) took 93.2s, 1628233 effective words/s\n",
      "2020-06-16 15:20:34,488 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-06-16 15:20:34,489 : INFO : training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-06-16 15:20:35,495 : INFO : EPOCH 1 - PROGRESS: at 4.75% examples, 1465320 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:36,497 : INFO : EPOCH 1 - PROGRESS: at 9.48% examples, 1485967 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:20:37,509 : INFO : EPOCH 1 - PROGRESS: at 12.94% examples, 1416474 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:38,514 : INFO : EPOCH 1 - PROGRESS: at 17.00% examples, 1409593 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:39,527 : INFO : EPOCH 1 - PROGRESS: at 20.70% examples, 1409770 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:20:40,530 : INFO : EPOCH 1 - PROGRESS: at 25.19% examples, 1430107 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:41,533 : INFO : EPOCH 1 - PROGRESS: at 29.78% examples, 1404743 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:20:42,534 : INFO : EPOCH 1 - PROGRESS: at 35.56% examples, 1435366 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:43,536 : INFO : EPOCH 1 - PROGRESS: at 41.79% examples, 1467013 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:44,542 : INFO : EPOCH 1 - PROGRESS: at 47.63% examples, 1484830 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:45,553 : INFO : EPOCH 1 - PROGRESS: at 53.07% examples, 1494771 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:46,561 : INFO : EPOCH 1 - PROGRESS: at 58.93% examples, 1509515 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:47,565 : INFO : EPOCH 1 - PROGRESS: at 64.72% examples, 1517022 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:20:48,567 : INFO : EPOCH 1 - PROGRESS: at 70.12% examples, 1527316 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:20:49,582 : INFO : EPOCH 1 - PROGRESS: at 75.95% examples, 1539295 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:50,592 : INFO : EPOCH 1 - PROGRESS: at 81.14% examples, 1544237 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:51,607 : INFO : EPOCH 1 - PROGRESS: at 86.98% examples, 1554448 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:52,608 : INFO : EPOCH 1 - PROGRESS: at 93.04% examples, 1564525 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:53,614 : INFO : EPOCH 1 - PROGRESS: at 99.08% examples, 1573519 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:53,723 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:20:53,732 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:20:53,738 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:20:53,739 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:20:53,741 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:20:53,746 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:20:53,747 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:20:53,748 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:20:53,748 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:20:53,752 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:20:53,753 : INFO : EPOCH - 1 : training on 41519358 raw words (30348852 effective words) took 19.3s, 1575823 effective words/s\n",
      "2020-06-16 15:20:54,761 : INFO : EPOCH 2 - PROGRESS: at 5.65% examples, 1733949 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:55,766 : INFO : EPOCH 2 - PROGRESS: at 10.85% examples, 1739319 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:20:56,775 : INFO : EPOCH 2 - PROGRESS: at 15.79% examples, 1733419 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:57,775 : INFO : EPOCH 2 - PROGRESS: at 20.30% examples, 1725446 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:58,788 : INFO : EPOCH 2 - PROGRESS: at 25.39% examples, 1728178 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:20:59,797 : INFO : EPOCH 2 - PROGRESS: at 31.95% examples, 1734704 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:00,799 : INFO : EPOCH 2 - PROGRESS: at 37.85% examples, 1731645 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:21:01,802 : INFO : EPOCH 2 - PROGRESS: at 44.16% examples, 1731720 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:02,803 : INFO : EPOCH 2 - PROGRESS: at 49.93% examples, 1722315 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:03,808 : INFO : EPOCH 2 - PROGRESS: at 55.78% examples, 1721564 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:04,816 : INFO : EPOCH 2 - PROGRESS: at 61.74% examples, 1721643 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 15:21:05,828 : INFO : EPOCH 2 - PROGRESS: at 67.54% examples, 1714806 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:21:06,839 : INFO : EPOCH 2 - PROGRESS: at 73.17% examples, 1711288 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:07,839 : INFO : EPOCH 2 - PROGRESS: at 78.71% examples, 1711892 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:21:08,843 : INFO : EPOCH 2 - PROGRESS: at 84.41% examples, 1713534 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:21:09,844 : INFO : EPOCH 2 - PROGRESS: at 90.50% examples, 1715378 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:21:10,846 : INFO : EPOCH 2 - PROGRESS: at 96.41% examples, 1715777 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:21:11,398 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:21:11,404 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:21:11,405 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:21:11,410 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:21:11,411 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:21:11,415 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:21:11,417 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:21:11,420 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:21:11,422 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:21:11,424 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:21:11,425 : INFO : EPOCH - 2 : training on 41519358 raw words (30351174 effective words) took 17.7s, 1717938 effective words/s\n",
      "2020-06-16 15:21:12,432 : INFO : EPOCH 3 - PROGRESS: at 5.33% examples, 1642582 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:21:13,438 : INFO : EPOCH 3 - PROGRESS: at 10.44% examples, 1661315 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:21:14,442 : INFO : EPOCH 3 - PROGRESS: at 14.70% examples, 1613373 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:21:15,450 : INFO : EPOCH 3 - PROGRESS: at 19.38% examples, 1637075 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:21:16,450 : INFO : EPOCH 3 - PROGRESS: at 24.22% examples, 1661198 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:21:17,453 : INFO : EPOCH 3 - PROGRESS: at 30.18% examples, 1663526 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:21:18,467 : INFO : EPOCH 3 - PROGRESS: at 36.40% examples, 1673140 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:21:19,475 : INFO : EPOCH 3 - PROGRESS: at 42.63% examples, 1680116 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:21:20,480 : INFO : EPOCH 3 - PROGRESS: at 48.78% examples, 1684920 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:21,482 : INFO : EPOCH 3 - PROGRESS: at 54.57% examples, 1688923 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:22,483 : INFO : EPOCH 3 - PROGRESS: at 60.68% examples, 1694338 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:21:23,492 : INFO : EPOCH 3 - PROGRESS: at 66.69% examples, 1695227 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:21:24,494 : INFO : EPOCH 3 - PROGRESS: at 72.46% examples, 1698740 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:25,504 : INFO : EPOCH 3 - PROGRESS: at 78.19% examples, 1701535 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:21:26,509 : INFO : EPOCH 3 - PROGRESS: at 83.96% examples, 1704204 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:27,520 : INFO : EPOCH 3 - PROGRESS: at 89.58% examples, 1698716 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:28,528 : INFO : EPOCH 3 - PROGRESS: at 95.73% examples, 1702974 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:21:29,191 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:21:29,198 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:21:29,199 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:21:29,200 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:21:29,203 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:21:29,212 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:21:29,216 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:21:29,217 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:21:29,218 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:21:29,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:21:29,219 : INFO : EPOCH - 3 : training on 41519358 raw words (30350377 effective words) took 17.8s, 1706172 effective words/s\n",
      "2020-06-16 15:21:30,230 : INFO : EPOCH 4 - PROGRESS: at 5.73% examples, 1757223 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:31,230 : INFO : EPOCH 4 - PROGRESS: at 11.00% examples, 1769660 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:21:32,240 : INFO : EPOCH 4 - PROGRESS: at 15.92% examples, 1753243 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:21:33,240 : INFO : EPOCH 4 - PROGRESS: at 20.49% examples, 1743588 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:34,247 : INFO : EPOCH 4 - PROGRESS: at 25.64% examples, 1744435 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:35,249 : INFO : EPOCH 4 - PROGRESS: at 32.03% examples, 1744160 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:36,259 : INFO : EPOCH 4 - PROGRESS: at 38.03% examples, 1740841 words/s, in_qsize 20, out_qsize 1\n",
      "2020-06-16 15:21:37,264 : INFO : EPOCH 4 - PROGRESS: at 44.35% examples, 1738401 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:38,264 : INFO : EPOCH 4 - PROGRESS: at 50.44% examples, 1738883 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:39,266 : INFO : EPOCH 4 - PROGRESS: at 56.31% examples, 1738388 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:21:40,274 : INFO : EPOCH 4 - PROGRESS: at 62.39% examples, 1739614 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:41,281 : INFO : EPOCH 4 - PROGRESS: at 68.49% examples, 1739800 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:21:42,284 : INFO : EPOCH 4 - PROGRESS: at 74.38% examples, 1740340 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:21:43,284 : INFO : EPOCH 4 - PROGRESS: at 79.73% examples, 1736334 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:21:44,295 : INFO : EPOCH 4 - PROGRESS: at 85.48% examples, 1737761 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:21:45,298 : INFO : EPOCH 4 - PROGRESS: at 91.76% examples, 1738947 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:21:46,306 : INFO : EPOCH 4 - PROGRESS: at 97.72% examples, 1738747 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:46,646 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:21:46,654 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:21:46,655 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:21:46,658 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:21:46,659 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:21:46,665 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:21:46,669 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:21:46,669 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:21:46,670 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:21:46,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:21:46,677 : INFO : EPOCH - 4 : training on 41519358 raw words (30347863 effective words) took 17.5s, 1738816 effective words/s\n",
      "2020-06-16 15:21:47,685 : INFO : EPOCH 5 - PROGRESS: at 5.47% examples, 1682597 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:21:48,690 : INFO : EPOCH 5 - PROGRESS: at 10.79% examples, 1724518 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:49,694 : INFO : EPOCH 5 - PROGRESS: at 15.78% examples, 1732516 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:50,694 : INFO : EPOCH 5 - PROGRESS: at 20.22% examples, 1719112 words/s, in_qsize 17, out_qsize 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 15:21:51,700 : INFO : EPOCH 5 - PROGRESS: at 25.24% examples, 1722616 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:21:52,713 : INFO : EPOCH 5 - PROGRESS: at 31.68% examples, 1724201 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:53,714 : INFO : EPOCH 5 - PROGRESS: at 37.76% examples, 1729950 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:54,718 : INFO : EPOCH 5 - PROGRESS: at 44.14% examples, 1732878 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:21:55,721 : INFO : EPOCH 5 - PROGRESS: at 50.30% examples, 1734189 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:56,723 : INFO : EPOCH 5 - PROGRESS: at 56.15% examples, 1733262 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:21:57,729 : INFO : EPOCH 5 - PROGRESS: at 61.89% examples, 1726554 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:21:58,733 : INFO : EPOCH 5 - PROGRESS: at 68.07% examples, 1729718 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:21:59,744 : INFO : EPOCH 5 - PROGRESS: at 74.02% examples, 1730972 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:00,749 : INFO : EPOCH 5 - PROGRESS: at 79.47% examples, 1729560 words/s, in_qsize 20, out_qsize 0\n",
      "2020-06-16 15:22:01,752 : INFO : EPOCH 5 - PROGRESS: at 85.17% examples, 1730942 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:02,753 : INFO : EPOCH 5 - PROGRESS: at 91.20% examples, 1729161 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:03,756 : INFO : EPOCH 5 - PROGRESS: at 97.09% examples, 1728499 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:04,192 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:22:04,199 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:22:04,201 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:22:04,202 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:22:04,206 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:22:04,207 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:22:04,211 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:22:04,216 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:22:04,218 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:22:04,221 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:22:04,224 : INFO : EPOCH - 5 : training on 41519358 raw words (30344954 effective words) took 17.5s, 1729833 effective words/s\n",
      "2020-06-16 15:22:05,238 : INFO : EPOCH 6 - PROGRESS: at 5.57% examples, 1701951 words/s, in_qsize 20, out_qsize 0\n",
      "2020-06-16 15:22:06,240 : INFO : EPOCH 6 - PROGRESS: at 10.76% examples, 1718794 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:07,250 : INFO : EPOCH 6 - PROGRESS: at 15.73% examples, 1721689 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:08,263 : INFO : EPOCH 6 - PROGRESS: at 20.41% examples, 1727096 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:09,271 : INFO : EPOCH 6 - PROGRESS: at 25.49% examples, 1729434 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:10,279 : INFO : EPOCH 6 - PROGRESS: at 31.14% examples, 1696514 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:11,288 : INFO : EPOCH 6 - PROGRESS: at 36.91% examples, 1689206 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:12,302 : INFO : EPOCH 6 - PROGRESS: at 43.04% examples, 1688269 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:13,306 : INFO : EPOCH 6 - PROGRESS: at 49.25% examples, 1692907 words/s, in_qsize 20, out_qsize 0\n",
      "2020-06-16 15:22:14,312 : INFO : EPOCH 6 - PROGRESS: at 55.23% examples, 1700518 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:15,323 : INFO : EPOCH 6 - PROGRESS: at 60.32% examples, 1678521 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:16,328 : INFO : EPOCH 6 - PROGRESS: at 66.33% examples, 1680928 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:17,331 : INFO : EPOCH 6 - PROGRESS: at 71.50% examples, 1671430 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:18,331 : INFO : EPOCH 6 - PROGRESS: at 76.48% examples, 1659578 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:19,348 : INFO : EPOCH 6 - PROGRESS: at 81.11% examples, 1643637 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:20,352 : INFO : EPOCH 6 - PROGRESS: at 86.61% examples, 1643420 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:21,352 : INFO : EPOCH 6 - PROGRESS: at 92.34% examples, 1641446 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:22,363 : INFO : EPOCH 6 - PROGRESS: at 98.10% examples, 1643836 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:22,653 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:22:22,657 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:22:22,658 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:22:22,659 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:22:22,663 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:22:22,667 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:22:22,669 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:22:22,670 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:22:22,677 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:22:22,678 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:22:22,679 : INFO : EPOCH - 6 : training on 41519358 raw words (30345582 effective words) took 18.4s, 1644796 effective words/s\n",
      "2020-06-16 15:22:23,686 : INFO : EPOCH 7 - PROGRESS: at 5.45% examples, 1677015 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:24,692 : INFO : EPOCH 7 - PROGRESS: at 10.66% examples, 1699583 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:25,705 : INFO : EPOCH 7 - PROGRESS: at 15.43% examples, 1690075 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:26,711 : INFO : EPOCH 7 - PROGRESS: at 20.10% examples, 1701325 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:27,713 : INFO : EPOCH 7 - PROGRESS: at 24.32% examples, 1665013 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:28,727 : INFO : EPOCH 7 - PROGRESS: at 30.44% examples, 1669690 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:22:29,740 : INFO : EPOCH 7 - PROGRESS: at 35.80% examples, 1645864 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:22:30,746 : INFO : EPOCH 7 - PROGRESS: at 41.89% examples, 1648822 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:31,748 : INFO : EPOCH 7 - PROGRESS: at 48.05% examples, 1659463 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:32,761 : INFO : EPOCH 7 - PROGRESS: at 53.84% examples, 1662557 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:33,774 : INFO : EPOCH 7 - PROGRESS: at 59.70% examples, 1662074 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:34,775 : INFO : EPOCH 7 - PROGRESS: at 65.66% examples, 1665245 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:35,777 : INFO : EPOCH 7 - PROGRESS: at 71.24% examples, 1667544 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:36,779 : INFO : EPOCH 7 - PROGRESS: at 76.50% examples, 1660791 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:37,781 : INFO : EPOCH 7 - PROGRESS: at 81.37% examples, 1650822 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:38,783 : INFO : EPOCH 7 - PROGRESS: at 86.46% examples, 1643612 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:39,794 : INFO : EPOCH 7 - PROGRESS: at 90.78% examples, 1617029 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:40,806 : INFO : EPOCH 7 - PROGRESS: at 96.10% examples, 1613158 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:22:41,449 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:22:41,462 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:22:41,467 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:22:41,467 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:22:41,469 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:22:41,479 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 15:22:41,482 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:22:41,484 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:22:41,485 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:22:41,490 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:22:41,491 : INFO : EPOCH - 7 : training on 41519358 raw words (30345535 effective words) took 18.8s, 1613528 effective words/s\n",
      "2020-06-16 15:22:42,502 : INFO : EPOCH 8 - PROGRESS: at 4.01% examples, 1236079 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:43,510 : INFO : EPOCH 8 - PROGRESS: at 8.65% examples, 1328686 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:22:44,517 : INFO : EPOCH 8 - PROGRESS: at 13.01% examples, 1421618 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:45,519 : INFO : EPOCH 8 - PROGRESS: at 17.69% examples, 1477634 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:46,529 : INFO : EPOCH 8 - PROGRESS: at 22.45% examples, 1517116 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:47,530 : INFO : EPOCH 8 - PROGRESS: at 26.42% examples, 1486149 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:48,543 : INFO : EPOCH 8 - PROGRESS: at 32.68% examples, 1518363 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:49,552 : INFO : EPOCH 8 - PROGRESS: at 38.50% examples, 1535977 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:50,554 : INFO : EPOCH 8 - PROGRESS: at 44.01% examples, 1533927 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:22:51,563 : INFO : EPOCH 8 - PROGRESS: at 49.61% examples, 1538364 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:52,565 : INFO : EPOCH 8 - PROGRESS: at 54.37% examples, 1528560 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:53,577 : INFO : EPOCH 8 - PROGRESS: at 59.49% examples, 1521333 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:54,580 : INFO : EPOCH 8 - PROGRESS: at 65.46% examples, 1534056 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:55,581 : INFO : EPOCH 8 - PROGRESS: at 70.98% examples, 1545422 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:56,587 : INFO : EPOCH 8 - PROGRESS: at 76.78% examples, 1557042 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:22:57,593 : INFO : EPOCH 8 - PROGRESS: at 82.24% examples, 1564341 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:58,603 : INFO : EPOCH 8 - PROGRESS: at 87.35% examples, 1561569 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:22:59,611 : INFO : EPOCH 8 - PROGRESS: at 91.98% examples, 1546898 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:23:00,620 : INFO : EPOCH 8 - PROGRESS: at 96.55% examples, 1535482 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:01,375 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:23:01,384 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:23:01,388 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:23:01,390 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:23:01,392 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:23:01,395 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:23:01,399 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:23:01,406 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:23:01,408 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:23:01,409 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:23:01,410 : INFO : EPOCH - 8 : training on 41519358 raw words (30352470 effective words) took 19.9s, 1524279 effective words/s\n",
      "2020-06-16 15:23:02,432 : INFO : EPOCH 9 - PROGRESS: at 4.38% examples, 1326727 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:03,436 : INFO : EPOCH 9 - PROGRESS: at 8.88% examples, 1365363 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:23:04,438 : INFO : EPOCH 9 - PROGRESS: at 12.50% examples, 1366852 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:23:05,444 : INFO : EPOCH 9 - PROGRESS: at 16.74% examples, 1385272 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:06,451 : INFO : EPOCH 9 - PROGRESS: at 20.42% examples, 1384950 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:23:07,458 : INFO : EPOCH 9 - PROGRESS: at 24.54% examples, 1399989 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:23:08,466 : INFO : EPOCH 9 - PROGRESS: at 30.17% examples, 1419725 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:09,470 : INFO : EPOCH 9 - PROGRESS: at 35.84% examples, 1442792 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:23:10,472 : INFO : EPOCH 9 - PROGRESS: at 41.27% examples, 1450248 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:23:11,474 : INFO : EPOCH 9 - PROGRESS: at 46.87% examples, 1461115 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:23:12,489 : INFO : EPOCH 9 - PROGRESS: at 52.33% examples, 1470641 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:13,499 : INFO : EPOCH 9 - PROGRESS: at 57.31% examples, 1467970 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:23:14,502 : INFO : EPOCH 9 - PROGRESS: at 62.68% examples, 1474808 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:23:15,505 : INFO : EPOCH 9 - PROGRESS: at 68.65% examples, 1491826 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:16,514 : INFO : EPOCH 9 - PROGRESS: at 74.42% examples, 1506124 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:17,531 : INFO : EPOCH 9 - PROGRESS: at 79.93% examples, 1518829 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:23:18,541 : INFO : EPOCH 9 - PROGRESS: at 85.37% examples, 1527098 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:23:19,545 : INFO : EPOCH 9 - PROGRESS: at 91.33% examples, 1534848 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:23:20,546 : INFO : EPOCH 9 - PROGRESS: at 96.97% examples, 1540892 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:21,126 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:23:21,136 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:23:21,137 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:23:21,140 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:23:21,144 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:23:21,146 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:23:21,152 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:23:21,155 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:23:21,158 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:23:21,161 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:23:21,162 : INFO : EPOCH - 9 : training on 41519358 raw words (30346339 effective words) took 19.7s, 1536859 effective words/s\n",
      "2020-06-16 15:23:22,173 : INFO : EPOCH 10 - PROGRESS: at 4.88% examples, 1495842 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:23,181 : INFO : EPOCH 10 - PROGRESS: at 9.20% examples, 1423914 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:24,186 : INFO : EPOCH 10 - PROGRESS: at 12.69% examples, 1390748 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:23:25,199 : INFO : EPOCH 10 - PROGRESS: at 16.13% examples, 1329313 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:23:26,205 : INFO : EPOCH 10 - PROGRESS: at 19.75% examples, 1333178 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:27,205 : INFO : EPOCH 10 - PROGRESS: at 23.62% examples, 1341718 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:23:28,211 : INFO : EPOCH 10 - PROGRESS: at 28.24% examples, 1342600 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:29,225 : INFO : EPOCH 10 - PROGRESS: at 33.35% examples, 1350787 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:23:30,230 : INFO : EPOCH 10 - PROGRESS: at 38.50% examples, 1364909 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:31,236 : INFO : EPOCH 10 - PROGRESS: at 43.94% examples, 1377500 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:32,243 : INFO : EPOCH 10 - PROGRESS: at 49.38% examples, 1391487 words/s, in_qsize 16, out_qsize 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 15:23:33,247 : INFO : EPOCH 10 - PROGRESS: at 54.10% examples, 1393789 words/s, in_qsize 16, out_qsize 3\n",
      "2020-06-16 15:23:34,248 : INFO : EPOCH 10 - PROGRESS: at 59.44% examples, 1403712 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:23:35,254 : INFO : EPOCH 10 - PROGRESS: at 65.09% examples, 1415927 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:23:36,262 : INFO : EPOCH 10 - PROGRESS: at 70.30% examples, 1427349 words/s, in_qsize 17, out_qsize 2\n",
      "2020-06-16 15:23:37,263 : INFO : EPOCH 10 - PROGRESS: at 76.18% examples, 1447900 words/s, in_qsize 20, out_qsize 0\n",
      "2020-06-16 15:23:38,264 : INFO : EPOCH 10 - PROGRESS: at 81.65% examples, 1462831 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:23:39,266 : INFO : EPOCH 10 - PROGRESS: at 87.54% examples, 1478146 words/s, in_qsize 18, out_qsize 1\n",
      "2020-06-16 15:23:40,268 : INFO : EPOCH 10 - PROGRESS: at 93.62% examples, 1492427 words/s, in_qsize 19, out_qsize 0\n",
      "2020-06-16 15:23:41,269 : INFO : EPOCH 10 - PROGRESS: at 99.62% examples, 1504566 words/s, in_qsize 15, out_qsize 0\n",
      "2020-06-16 15:23:41,294 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-06-16 15:23:41,300 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-06-16 15:23:41,305 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-06-16 15:23:41,306 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-06-16 15:23:41,312 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-06-16 15:23:41,317 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-06-16 15:23:41,318 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-06-16 15:23:41,325 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-16 15:23:41,327 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-16 15:23:41,328 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-16 15:23:41,329 : INFO : EPOCH - 10 : training on 41519358 raw words (30347732 effective words) took 20.2s, 1505252 effective words/s\n",
      "2020-06-16 15:23:41,330 : INFO : training on a 415193580 raw words (303480878 effective words) took 186.8s, 1624277 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(303480878, 415193580)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's look at some output \n",
    "This first example shows a simple case of looking up words similar to the word `dirty`. All we need to do here is to call the `most_similar` function and provide the word `dirty` as the positive example. This returns the top 10 similar words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w1 = \"dirty\"\n",
    "model.wv.most_similar (positive=w1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good, right? Let's look at a few more. Let's look at similarity for `polite`, `france` and `shocked`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up top 6 words similar to 'polite'\n",
    "w1 = [\"polite\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up top 6 words similar to 'france'\n",
    "w1 = [\"france\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up top 6 words similar to 'shocked'\n",
    "w1 = [\"shocked\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's, nice. You can even specify several positive examples to get things that are related in the provided context and provide negative examples to say what should not be considered as related. In the example below we are asking for all items that *relate to bed* only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get everything related to stuff on the bed\n",
    "w1 = [\"bed\",'sheet','pillow']\n",
    "w2 = ['couch']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between two words in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even use the Word2Vec model to return the similarity between two words that are present in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity between two different words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"smelly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity between two identical words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity between two unrelated words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the above three snippets computes the cosine similarity between the two specified words using word vectors of each. From the scores, it makes sense that `dirty` is highly similar to `smelly` but `dirty` is dissimilar to `clean`. If you do a similarity between two identical words, the score will be 1.0 as the range of the cosine similarity score will always be between [0.0-1.0]. You can read more about cosine similarity scoring [here](https://en.wikipedia.org/wiki/Cosine_similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the odd one out\n",
    "You can even use Word2Vec to find odd items given a list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding some of the parameters\n",
    "To train the model earlier, we had to set some parameters. Now, let's try to understand what some of them mean. For reference, this is the command that we used to train the model.\n",
    "\n",
    "```\n",
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "```\n",
    "\n",
    "### `size`\n",
    "The size of the dense vector to represent each token or word. If you have very limited data, then size should be a much smaller value. If you have lots of data, its good to experiment with various sizes. A value of 100-150 has worked well for me. \n",
    "\n",
    "### `window`\n",
    "The maximum distance between the target word and its neighboring word. If your neighbor's position is greater than the maximum window width to the left and the right, then, some neighbors are not considered as being related to the target word. In theory, a smaller window should give you terms that are more related. If you have lots of data, then the window size should not matter too much, as long as its a decent sized window. \n",
    "\n",
    "### `min_count`\n",
    "Minimium frequency count of words. The model would ignore words that do not statisfy the `min_count`. Extremely infrequent words are usually unimportant, so its best to get rid of those. Unless your dataset is really tiny, this does not really affect the model.\n",
    "\n",
    "### `workers`\n",
    "How many threads to use behind the scenes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When should you use Word2Vec?\n",
    "\n",
    "There are many application scenarios for Word2Vec. Imagine if you need to build a sentiment lexicon. Training a Word2Vec model on large amounts of user reviews helps you achieve that. You have a lexicon for not just sentiment, but for most words in the vocabulary. \n",
    "\n",
    "Beyond, raw unstructured text data, you could also use Word2Vec for more structured data. For example, if you had tags for a million stackoverflow questions and answers, you could find tags that are related to a given tag and recommend the related ones for exploration. You can do this by treating each set of co-occuring tags as a \"sentence\" and train a Word2Vec model on this data. Granted, you still need a large number of examples to make it work. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.98078227e+00, -9.06566024e-01, -1.34488329e-01, -5.06701756e+00,\n",
       "        1.52403259e+00, -3.95868564e+00,  2.04536891e+00, -3.71955180e+00,\n",
       "        1.74870801e+00,  1.72618759e+00, -5.17557716e+00, -3.03478628e-01,\n",
       "        2.88443565e+00,  4.68250418e+00,  3.72485495e+00, -7.50020885e+00,\n",
       "        1.38099241e+00, -5.20219803e-01,  5.00840187e-01,  1.85577202e+00,\n",
       "        3.22760773e+00, -2.51910901e+00,  7.05691874e-01,  2.68260121e-01,\n",
       "        7.77740300e-01, -2.86655974e+00, -3.14675546e+00, -5.54975843e+00,\n",
       "        3.14233947e+00,  3.96534038e+00, -3.96096754e+00,  1.98728049e+00,\n",
       "        2.33296466e+00,  3.40679944e-01, -2.71325618e-01,  8.66360486e-01,\n",
       "       -8.76150072e-01,  2.02023840e+00, -1.92977881e+00, -3.56002331e+00,\n",
       "        8.79617453e-01,  3.02764028e-01,  2.13232636e+00,  3.07156473e-01,\n",
       "       -2.11493230e+00,  5.12150349e-03, -2.14534473e+00, -9.21717465e-01,\n",
       "        3.67876244e+00,  3.16294146e+00,  2.78425837e+00,  2.01577902e+00,\n",
       "        4.85608354e-02, -4.37730074e+00, -9.63790566e-02, -1.33834374e+00,\n",
       "        1.63235462e+00,  4.15529394e+00,  5.03813565e-01,  8.57451499e-01,\n",
       "       -1.63066840e+00,  5.68994820e-01, -4.99904680e+00, -2.94066286e+00,\n",
       "        1.67453158e+00,  1.77164185e+00, -3.30645061e+00, -3.43346596e+00,\n",
       "       -1.61293304e+00, -3.56616229e-01, -1.13927074e-01,  2.82361746e+00,\n",
       "       -2.27041030e+00, -2.77365637e+00, -2.86720467e+00,  1.10777426e+00,\n",
       "        2.40664467e-01, -3.00586987e+00,  1.90399861e+00, -2.23484254e+00,\n",
       "       -1.55675745e+00,  2.04978275e+00, -3.29787874e+00, -9.98549283e-01,\n",
       "        8.68642390e-01, -3.91873837e-01, -8.10643196e-01,  2.29744482e+00,\n",
       "       -2.03393626e+00,  1.67780340e+00, -4.34127569e+00,  9.30208504e-01,\n",
       "       -4.10707617e+00,  1.32641351e+00,  1.66261625e+00,  1.81750643e+00,\n",
       "       -6.23139441e-01, -2.65638399e+00,  1.95416582e+00,  2.71078467e+00,\n",
       "        2.75559127e-01, -3.16075492e+00, -3.23719072e+00, -1.25127530e+00,\n",
       "        3.56138563e+00,  1.43136501e+00,  1.55235708e+00,  6.85434416e-02,\n",
       "       -1.18126190e+00,  1.97082400e+00,  8.20557833e-01, -1.31899059e+00,\n",
       "       -1.77535856e+00,  1.78129494e+00,  7.03620195e-01, -1.06131506e+00,\n",
       "        2.40808439e+00,  2.28015256e+00,  2.62320065e+00,  2.97780943e+00,\n",
       "        1.59243035e+00,  4.40325141e-01, -2.50064993e+00,  3.13363576e+00,\n",
       "       -2.90102816e+00, -1.85495770e+00, -5.55379212e-01, -3.56766367e+00,\n",
       "        8.93401146e-01, -1.51143298e-01, -4.84181833e+00, -3.48979139e+00,\n",
       "       -1.36885369e+00, -1.28480899e+00,  2.82541442e+00, -1.55988947e-01,\n",
       "       -1.56171727e+00, -1.52472603e+00,  2.54344434e-01,  5.23255396e+00,\n",
       "       -2.56148195e+00, -3.30293036e+00, -4.35689783e+00, -1.87096620e+00,\n",
       "        2.04141736e+00, -1.97968638e+00, -3.48793554e+00, -1.19067609e+00,\n",
       "       -3.88726711e+00,  3.47431564e+00], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can store/load models using the standard gensim methods\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model.save(\"word2vec.model\")\n",
    "\n",
    "new_model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "# 加载模型后再训练\n",
    "new_model.train([[\"hello\", \"world\"]], total_examples=1, epochs=1)\n",
    "\n",
    "new_model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])\n",
    "new_model['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练中文的例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词\n",
    "首先使用jieba分词工具对文本进行分词处理，处理完成放置到新的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "\n",
    "# suggest_freq 设置词为整体，不被分离\n",
    "\n",
    "jieba.suggest_freq('沙瑞金', True)\n",
    "jieba.suggest_freq('田国富', True)\n",
    "jieba.suggest_freq('高育良', True)\n",
    "jieba.suggest_freq('侯亮平', True)\n",
    "jieba.suggest_freq('钟小艾', True)\n",
    "jieba.suggest_freq('陈岩石', True)\n",
    "jieba.suggest_freq('欧阳菁', True)\n",
    "jieba.suggest_freq('易学习', True)\n",
    "jieba.suggest_freq('王大路', True)\n",
    "jieba.suggest_freq('蔡成功', True)\n",
    "jieba.suggest_freq('孙连城', True)\n",
    "jieba.suggest_freq('季昌明', True)\n",
    "jieba.suggest_freq('丁义珍', True)\n",
    "jieba.suggest_freq('郑西坡', True)\n",
    "jieba.suggest_freq('赵东来', True)\n",
    "jieba.suggest_freq('高小琴', True)\n",
    "jieba.suggest_freq('赵瑞龙', True)\n",
    "jieba.suggest_freq('林华华', True)\n",
    "jieba.suggest_freq('陆亦可', True)\n",
    "jieba.suggest_freq('刘新建', True)\n",
    "jieba.suggest_freq('刘庆祝', True)\n",
    "\n",
    "with open('../corpus/in_the_name_of_people.txt', 'rb') as f:\n",
    "    document = f.read()\n",
    "#     document_decode = document.decode('GBK')\n",
    "    document_cut = jieba.cut(document)\n",
    "    result = ' '.join(document_cut)\n",
    "    result = result.encode('utf-8')\n",
    "    with open('../corpus/in_the_name_of_people_segment.txt', 'wb') as f2:\n",
    "        f2.write(result)\n",
    "\n",
    "f.close()\n",
    "f2.close()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "\n",
    "min_word_count = 10 # ⼀个word，最少出现多少次 才被计⼊\n",
    "num_workers = 1 # 多少thread⼀起跑（快⼀点⼉）\n",
    "size = 300 # vec的size\n",
    "window = 3 # 前后观察多⻓的“语境”\n",
    "\n",
    "\n",
    "sentences = word2vec.LineSentence('../corpus/in_the_name_of_people_segment.txt') \n",
    "\n",
    "\n",
    "model = word2vec.Word2Vec(sentences, size=size, workers=num_workers, \\\n",
    "                          min_count = min_word_count, \\\n",
    "                          window = window)\n",
    "\n",
    "model.train(sentences, total_examples=sentences.max_sentence_length, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型词典库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in model.wv.vocab.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相似度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='侯亮平')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('沙发', '我')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 与侯亮平最相似的前10个，只显示三个字的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in model.wv.similar_by_word('侯亮平', topn=10):\n",
    "    if len(value[0]) == 3:\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.__getitem__('人民')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
